
Render Pipeline
	
	PASS #1
		Targets
			Albedo (texture) color, RGB8
			Position, RGB16
			Normal, RG16 (reconstruct z - has to be camera space and invert?)
			Light, RGB16 [torch, sun, ao]
			Depth 
		ToDo - do we replace torch/sun/ao/albedo with 3D texture coordinates? the texturing can have problems with uv gradient, especially on tiling quads. Don't _really_ need to do this.

		Render skydome - output color / clear position, normal, light, maximum depth
		Render stars - same
		Render chunks 
	PASS #2
		Bind Albedo, Position, Normal, Light, Depth (later, can stay buffered for now)
		Calculate light in HDR
		tone mapping within; don't need float color buffer otherwise
			unless we are doing some sort of light accumulation buffer?

		Things to calculate:
			Debug light views
			Torch
			Sun + daylight
			Dynamic light
			Fog


#version 330 core

flat in uint f_t, f_ql, f_qs;
flat in vec4 f_ao;
flat in vec4 f_l, f_s;
in vec2 f_uv;
in vec3 f_n;
in float f_ah, f_d;
in vec3 f_pos;

layout (location = 0) out vec4 out_color;

uniform sampler2DArray blocks_tex;
uniform sampler2D sky_tex;

uniform bool do_fog;
uniform bool do_light;
uniform bool smooth_light;
uniform bool dynamic_light;

uniform vec3 light_col;
uniform vec3 light_pos;
uniform int debug_light;

uniform float render_distance;
uniform float day_01;
uniform float ambient;

const float PI = 3.14159265f;

void main() {


	vec3 uvt = vec3(f_uv, f_t);
	vec3 color = texture(blocks_tex, uvt).rgb;

	vec3 total_light = vec3(0.0f);
	float ao = 1.0f;

	if(do_light) {

		float day_factor = 1.0f - (smoothstep(0.32f, 0.17f, day_01) + smoothstep(0.75f, 0.9f, day_01));

		float ao0 = mix(f_ao.x, f_ao.y, fract(f_uv.x));
		float ao1 = mix(f_ao.z, f_ao.w, fract(f_uv.x));
		ao = mix(ao0, ao1, fract(f_uv.y));

		if(smooth_light) {

			float t0 = mix(f_l.x, f_l.y, fract(f_uv.x));
			float t1 = mix(f_l.z, f_l.w, fract(f_uv.x));
			float t = mix(t0, t1, fract(f_uv.y));

			float s0 = mix(f_s.x, f_s.y, fract(f_uv.x));
			float s1 = mix(f_s.z, f_s.w, fract(f_uv.x));
			float s = mix(s0, s1, fract(f_uv.y)) * day_factor;

			float l = max(t,s);
			total_light += vec3(pow(l,3));

		} else {

			float t = float(f_ql) / 15.0f;
			float s = float(f_qs) / 15.0f * day_factor;
			float l = max(t,s);
			total_light += vec3(pow(l,3));
		}
	}

	total_light *= ao;

	if(dynamic_light && smooth_light) {
		vec3 p = f_pos;
		vec3 n = normalize(f_n);
		vec3 v = normalize(-p);
		vec3 l = normalize(light_pos-p);
		vec3 h = normalize(l + v);

		float dist = length(light_pos-p);
		float a = min(1.0f / pow(dist,3), 1.0f);

		float diff = max(dot(n,l), 0.0f);
		total_light += diff * light_col * a;
			
		float shine = 64.0f;
		float energy = (8.0f + shine) / (8.0f * PI); 
   		float spec = 0.5f * energy * pow(max(dot(n, h), 0.0), shine);

		total_light += spec * light_col * a;
	}

	color *= ambient + total_light;

	if(do_fog) {

		float fog_factor = smoothstep(0.9f, 1.0f, f_d / render_distance);
		vec3 sky_color = texture(sky_tex, vec2(day_01, f_ah)).rgb;

		color = mix(color, sky_color, fog_factor);
	}

	out_color = vec4(color, 1.0f);
}



Chunk Staging

	populated -> generated -> lit[sync neighbors] -> meshed[sync neighbors]

	Do we combine lighting/meshing steps? Yes

Vertex Format

	Quads

	0000 0000 0000 0000 0000 0000 0000 0000
	xxxx xxxx zzzz zzzz xxxx xxxx zzzz zzzz

	0000 0000 0000 0000 0000 0000 0000 0000
	xxxx xxxx zzzz zzzz xxxx xxxx zzzz zzzz

	0000 0000 0000 0000 0000 0000 0000 0000
	yyyy yyyy yyyy yyyy yyyy yyyy uuuu uuuu

	0000 0000 0000 0000 0000 0000 0000 0000
	yyyy yyyy yyyy yyyy yyyy yyyy vvvv vvvv

	+q

	0000 0000 0000 0000 0000 0000 0000 0000
	tttt tttt tttt tttt llll llll aoao aoao

	0000 0000 0000 0000 0000 0000 0000 0000
	l0l0 l0l0 l1l1 l1l1 l2l2 l2l2 l3l3 l3l3

	0000 0000 0000 0000 0000 0000 0000 0000
	l0l0 l0l0 l1l1 l1l1 l2l2 l2l2 l3l3 l3l3

old -

===FACE APPROACH===

	Each face represented as a uvec4

	u32                                     | u32                                     | u32
	256|32    256|32    256       256       | 4096|512       4096           4 4  4 4  | 256       256       256       256
	0000 0000 0000 0000 0000 0000 0000 0000 | 0000 0000 0000 0000 0000 0000 0000 0000 | 0000 0000 0000 0000 0000 0000 0000 0000
	xxxx xxxx zzzz zzzz uuuu uuuu vvvv vvvv | yyyy yyyy yyyy tttt tttt tttt a0a1 a2a3 | tttt tttt uuuu uuuu vvvv vvvv tttt tttt

	u32                                    
	
	0000 0000 0000 0000 0000 0000 0000 0000
	ddbf 0000 0001 1111 1122 2222 2333 3333

	Microblocks -> 8 units / voxel, meaning X/Y/Z/U/V are divided by 8, and UV patches can only be XZ sized (32x32)

	Chunk is 32x32x512

	Do we want to modify this for LOD?

	The geometry shader approach is actually like 30% slower than everything per-vertex. However, it does use 4x less GPU memory...
